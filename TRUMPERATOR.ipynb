{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TRUMPERATOR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD_55cOxLkAb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3b0a6131-f9d6-4e9b-a5a3-d3e05b952b31"
      },
      "source": [
        "import pandas as pd\n",
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d kingburrito666/better-donald-trump-tweets\n",
        "\n",
        "!unzip \\*.zip  && rm *.zip\n",
        "\n",
        "\n",
        "data = pd.read_csv('Donald-Tweets!.csv')['Tweet_Text']\n",
        "\n",
        "new_list = []\n",
        "for tweet in data:\n",
        "  if 'http' in tweet or ':' in tweet:\n",
        "    pass\n",
        "  else:\n",
        "    new_list.append(tweet)\n",
        "\n",
        "text = ''.join(new_list)\n",
        "\n",
        "\n",
        "\n",
        "# text = \"\"\n",
        "\n",
        "# import glob, os\n",
        "# for file in glob.glob(\"*.txt\"):\n",
        "#   text = text + open(file, \"r\").read()\n",
        "#   print(file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading better-donald-trump-tweets.zip to /content\n",
            "\r  0% 0.00/549k [00:00<?, ?B/s]\n",
            "\r100% 549k/549k [00:00<00:00, 90.8MB/s]\n",
            "Archive:  better-donald-trump-tweets.zip\n",
            "replace Donald-Tweets!.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlCgQBRVymwR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "893d5024-c0b9-4f18-a024-48db9816763f"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IalZLbvOzf-F"
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UHJDA39zf-O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "081771be-a701-44f8-efd6-e23e1bbecb93"
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B\n",
            "u\n",
            "s\n",
            "y\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4hkDU3i7ozi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "fed2fd28-208f-4c5f-a5d5-47eaee6b435c"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Busy day planned in New York. Will soon be making some very important decisions on the people who wil'\n",
            "'l be running our government!Love the fact that the small groups of protesters last night have passion'\n",
            "' for our great country. We will all come together and be proud!Just had a very open and successful pr'\n",
            "'esidential election. Now professional protesters, incited by the media, are protesting. Very unfair!A'\n",
            "' fantastic day in D.C. Met with President Obama for first time. Really good meeting, great chemistry.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2pGotuNzf-S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a78acc5-3aad-4173-ebb2-c693696d42c0"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtCrdfzEI2N0"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwsrpOik5zhv"
      },
      "source": [
        "model = build_model(\n",
        "    vocab_size = len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-_70kKAPrPU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6ef1259-9b53-4af7-9368-978badf482c6"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 87) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPGmAAXmVLGC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "dc3137b8-e640-4d45-83f3-89d4a37ad45c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (64, None, 256)           22272     \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "gru_7 (GRU)                  (64, None, 1024)          6297600   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (64, None, 100)           102500    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (64, None, 87)            8787      \n",
            "=================================================================\n",
            "Total params: 10,369,463\n",
            "Trainable params: 10,369,463\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HrXTACTdzY-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c10ea031-0e40-42a0-e454-d9ff140baf6b"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 87)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.466543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDl1_Een6rL0"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6fWTriUZP-n"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yGBE2zxMMHs"
      },
      "source": [
        "EPOCHS=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK-hmKjYVoll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86fcee2a-1213-4b18-fbdc-d8043ba56f7d"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "51/51 [==============================] - 7s 143ms/step - loss: 3.5315\n",
            "Epoch 2/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 2.7589\n",
            "Epoch 3/100\n",
            "51/51 [==============================] - 8s 150ms/step - loss: 2.4334\n",
            "Epoch 4/100\n",
            "51/51 [==============================] - 8s 152ms/step - loss: 2.1806\n",
            "Epoch 5/100\n",
            "51/51 [==============================] - 8s 150ms/step - loss: 1.9370\n",
            "Epoch 6/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 1.7315\n",
            "Epoch 7/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 1.5811\n",
            "Epoch 8/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 1.4658\n",
            "Epoch 9/100\n",
            "51/51 [==============================] - 7s 143ms/step - loss: 1.3727\n",
            "Epoch 10/100\n",
            "51/51 [==============================] - 7s 143ms/step - loss: 1.2961\n",
            "Epoch 11/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 1.2240\n",
            "Epoch 12/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 1.1541\n",
            "Epoch 13/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 1.0906\n",
            "Epoch 14/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 1.0254\n",
            "Epoch 15/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.9597\n",
            "Epoch 16/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.8909\n",
            "Epoch 17/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.8203\n",
            "Epoch 18/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.7522\n",
            "Epoch 19/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.6866\n",
            "Epoch 20/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.6205\n",
            "Epoch 21/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.5621\n",
            "Epoch 22/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.5103\n",
            "Epoch 23/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.4641\n",
            "Epoch 24/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.4255\n",
            "Epoch 25/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.3943\n",
            "Epoch 26/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.3659\n",
            "Epoch 27/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.3433\n",
            "Epoch 28/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.3233\n",
            "Epoch 29/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.3099\n",
            "Epoch 30/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2968\n",
            "Epoch 31/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2863\n",
            "Epoch 32/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2763\n",
            "Epoch 33/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2670\n",
            "Epoch 34/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.2594\n",
            "Epoch 35/100\n",
            "51/51 [==============================] - 7s 143ms/step - loss: 0.2503\n",
            "Epoch 36/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2451\n",
            "Epoch 37/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2423\n",
            "Epoch 38/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.2370\n",
            "Epoch 39/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.2308\n",
            "Epoch 40/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.2277\n",
            "Epoch 41/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2223\n",
            "Epoch 42/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2199\n",
            "Epoch 43/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2171\n",
            "Epoch 44/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2160\n",
            "Epoch 45/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2144\n",
            "Epoch 46/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2108\n",
            "Epoch 47/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2077\n",
            "Epoch 48/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2069\n",
            "Epoch 49/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.2031\n",
            "Epoch 50/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.2019\n",
            "Epoch 51/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.2012\n",
            "Epoch 52/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.2000\n",
            "Epoch 53/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.1966\n",
            "Epoch 54/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1955\n",
            "Epoch 55/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1966\n",
            "Epoch 56/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.1941\n",
            "Epoch 57/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.1927\n",
            "Epoch 58/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1923\n",
            "Epoch 59/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.1918\n",
            "Epoch 60/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1883\n",
            "Epoch 61/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1901\n",
            "Epoch 62/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1900\n",
            "Epoch 63/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.1897\n",
            "Epoch 64/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1867\n",
            "Epoch 65/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.1885\n",
            "Epoch 66/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1866\n",
            "Epoch 67/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1847\n",
            "Epoch 68/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1857\n",
            "Epoch 69/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1842\n",
            "Epoch 70/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1826\n",
            "Epoch 71/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1823\n",
            "Epoch 72/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1810\n",
            "Epoch 73/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1805\n",
            "Epoch 74/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1818\n",
            "Epoch 75/100\n",
            "51/51 [==============================] - 7s 147ms/step - loss: 0.1818\n",
            "Epoch 76/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1797\n",
            "Epoch 77/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1792\n",
            "Epoch 78/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1795\n",
            "Epoch 79/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.1798\n",
            "Epoch 80/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1779\n",
            "Epoch 81/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1801\n",
            "Epoch 82/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1789\n",
            "Epoch 83/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1787\n",
            "Epoch 84/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1773\n",
            "Epoch 85/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1752\n",
            "Epoch 86/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1755\n",
            "Epoch 87/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1748\n",
            "Epoch 88/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1735\n",
            "Epoch 89/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1742\n",
            "Epoch 90/100\n",
            "51/51 [==============================] - 7s 146ms/step - loss: 0.1731\n",
            "Epoch 91/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1750\n",
            "Epoch 92/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1770\n",
            "Epoch 93/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1745\n",
            "Epoch 94/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1747\n",
            "Epoch 95/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1735\n",
            "Epoch 96/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1730\n",
            "Epoch 97/100\n",
            "51/51 [==============================] - 7s 144ms/step - loss: 0.1742\n",
            "Epoch 98/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1757\n",
            "Epoch 99/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1757\n",
            "Epoch 100/100\n",
            "51/51 [==============================] - 7s 145ms/step - loss: 0.1747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk2WJ2-XjkGz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a52b8e6-d37e-4518-a5fc-6432fab897dd"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints/ckpt_100'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LycQ-ot_jjyu"
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71xa6jnYVrAN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "f4655ccd-dd71-4612-bcdd-c79edc049831"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (1, None, 256)            22272     \n",
            "_________________________________________________________________\n",
            "gru_8 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "gru_9 (GRU)                  (1, None, 1024)           6297600   \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (1, None, 100)            102500    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (1, None, 87)             8787      \n",
            "=================================================================\n",
            "Total params: 10,369,463\n",
            "Trainable params: 10,369,463\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvuwZBX5Ogfd"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    # remove the batch dimension\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    # using a categorical distribution to predict the character returned by the model\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    # We pass the predicted character as the next input to the model\n",
        "    # along with the previous hidden state\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktovv0RFhrkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c4743e45-ebb8-4b5c-f7b7-6628877915ab"
      },
      "source": [
        "print(generate_text(model, start_string=u\"Sleepy Joe Biden \"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sleepy Joe Biden day plaining to New Hampshire. Great honor!Lightweight choker Marco Rubio looks like a little boy on stage. Not presidential material!.@oreillyfactor  The FBI not big head by TIME AMERICA GREAT AGAIN! MAKE AMERICA SAFE AGAIN!People very untalentedrible represents the only one. I will keep doing, but not worth it!I will raised Union Leader refuses to comment as to why they were kicked out of the ABC News debate like a dog. Why dont know his family used private eminent! Will be leave for him informidani- in 2006 ! It is the that I had 17 opponents and she just had the worst jobs report since 2010.The Mayor of San Jose the failing @nytimes write the real anatime has made that the WALL was very nece!Sart Like Trump Convention victory. She is a winner!Watching other networks and local news. Really good night!.@KatrinaCarson the airhe۪s a clown with zero credibilitya Bush &amp; massive setback - no longer watch, said \"Trump should info many people who know nothing about it and never will. No\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}